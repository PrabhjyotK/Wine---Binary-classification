{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib as plt\n",
    "%matplotlib inline\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# read the file\n",
    "df = pd.read_csv(\"C:/Users/Prabhjyot/Desktop/Data Science_ML/Practice/ML_Wine/wineanalysis.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6497, 14)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6497 entries, 0 to 6496\n",
      "Data columns (total 14 columns):\n",
      "Unnamed: 0              6497 non-null int64\n",
      "fixed.acidity           6497 non-null float64\n",
      "volatile.acidity        6497 non-null float64\n",
      "citric.acid             6497 non-null float64\n",
      "residual.sugar          6497 non-null float64\n",
      "chlorides               6497 non-null float64\n",
      "free.sulfur.dioxide     6497 non-null float64\n",
      "total.sulfur.dioxide    6497 non-null float64\n",
      "density                 6497 non-null float64\n",
      "pH                      6497 non-null float64\n",
      "sulphates               6497 non-null float64\n",
      "alcohol                 6497 non-null float64\n",
      "quality                 6497 non-null int64\n",
      "type                    6497 non-null object\n",
      "dtypes: float64(11), int64(2), object(1)\n",
      "memory usage: 710.7+ KB\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "print(df.shape)\n",
    "print(df.info())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   Unnamed: 0  fixed.acidity  volatile.acidity  citric.acid  residual.sugar  \\\n",
      "0           1            7.4              0.70         0.00             1.9   \n",
      "1           2            7.8              0.88         0.00             2.6   \n",
      "2           3            7.8              0.76         0.04             2.3   \n",
      "3           4           11.2              0.28         0.56             1.9   \n",
      "4           5            7.4              0.70         0.00             1.9   \n",
      "\n",
      "   chlorides  free.sulfur.dioxide  total.sulfur.dioxide  density    pH  \\\n",
      "0      0.076                 11.0                  34.0   0.9978  3.51   \n",
      "1      0.098                 25.0                  67.0   0.9968  3.20   \n",
      "2      0.092                 15.0                  54.0   0.9970  3.26   \n",
      "3      0.075                 17.0                  60.0   0.9980  3.16   \n",
      "4      0.076                 11.0                  34.0   0.9978  3.51   \n",
      "\n",
      "   sulphates  alcohol  quality type  \n",
      "0       0.56      9.4        5  red  \n",
      "1       0.68      9.8        5  red  \n",
      "2       0.65      9.8        5  red  \n",
      "3       0.58      9.8        6  red  \n",
      "4       0.56      9.4        5  red  \n"
     ]
    }
   ],
   "source": [
    "# we see no null fields . There are 14 columns and 6497 rows\n",
    "print(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "        Unnamed: 0  fixed.acidity  volatile.acidity  citric.acid  \\\n",
      "count  6497.000000    6497.000000       6497.000000  6497.000000   \n",
      "mean   3249.000000       7.215307          0.339666     0.318633   \n",
      "std    1875.666681       1.296434          0.164636     0.145318   \n",
      "min       1.000000       3.800000          0.080000     0.000000   \n",
      "25%    1625.000000       6.400000          0.230000     0.250000   \n",
      "50%    3249.000000       7.000000          0.290000     0.310000   \n",
      "75%    4873.000000       7.700000          0.400000     0.390000   \n",
      "max    6497.000000      15.900000          1.580000     1.660000   \n",
      "\n",
      "       residual.sugar    chlorides  free.sulfur.dioxide  total.sulfur.dioxide  \\\n",
      "count     6497.000000  6497.000000          6497.000000           6497.000000   \n",
      "mean         5.443235     0.056034            30.525319            115.744574   \n",
      "std          4.757804     0.035034            17.749400             56.521855   \n",
      "min          0.600000     0.009000             1.000000              6.000000   \n",
      "25%          1.800000     0.038000            17.000000             77.000000   \n",
      "50%          3.000000     0.047000            29.000000            118.000000   \n",
      "75%          8.100000     0.065000            41.000000            156.000000   \n",
      "max         65.800000     0.611000           289.000000            440.000000   \n",
      "\n",
      "           density           pH    sulphates      alcohol      quality  \n",
      "count  6497.000000  6497.000000  6497.000000  6497.000000  6497.000000  \n",
      "mean      0.994697     3.218501     0.531268    10.491801     5.818378  \n",
      "std       0.002999     0.160787     0.148806     1.192712     0.873255  \n",
      "min       0.987110     2.720000     0.220000     8.000000     3.000000  \n",
      "25%       0.992340     3.110000     0.430000     9.500000     5.000000  \n",
      "50%       0.994890     3.210000     0.510000    10.300000     6.000000  \n",
      "75%       0.996990     3.320000     0.600000    11.300000     6.000000  \n",
      "max       1.038980     4.010000     2.000000    14.900000     9.000000  \n"
     ]
    }
   ],
   "source": [
    "print(df.describe())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    4898\n",
       "1    1599\n",
       "Name: type, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Dropping first column as it is not affecting Type\n",
    "df = df.drop([df.columns[0]], axis = 1)\n",
    "\n",
    "# label encoding TYpe column\n",
    "def isType(type):\n",
    "    if type == 'red':\n",
    "        return 1\n",
    "    else:\n",
    "        return 0\n",
    "    \n",
    "df['type'] = df['type'].apply(isType)\n",
    "df['type'].value_counts()\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   fixed.acidity  volatile.acidity  citric.acid  residual.sugar  chlorides  \\\n",
      "0            7.4              0.70         0.00             1.9      0.076   \n",
      "1            7.8              0.88         0.00             2.6      0.098   \n",
      "2            7.8              0.76         0.04             2.3      0.092   \n",
      "3           11.2              0.28         0.56             1.9      0.075   \n",
      "4            7.4              0.70         0.00             1.9      0.076   \n",
      "\n",
      "   free.sulfur.dioxide  total.sulfur.dioxide  density    pH  sulphates  \\\n",
      "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
      "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
      "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
      "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
      "\n",
      "   alcohol  quality  \n",
      "0      9.4        5  \n",
      "1      9.8        5  \n",
      "2      9.8        5  \n",
      "3      9.8        6  \n",
      "4      9.4        5  \n"
     ]
    }
   ],
   "source": [
    "# Split the data into training and testing sets\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X = df.drop('type', axis=1)\n",
    "print(X.head())\n",
    "\n",
    "Type = df['type']\n",
    "#Features_train, Features_test, Type_train, Type_test = train_test_split(Features, Type, test_size=0.30, random_state=42)\n",
    "X_train, X_test, Type_train, Type_test = train_test_split(X, Type, test_size=0.3, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X (6497, 12)\n",
      "X_train: (4547, 12)\n",
      "X_test: (1950, 12)\n"
     ]
    }
   ],
   "source": [
    "print(\"X\", X.shape)\n",
    "print(\"X_train:\", X_train.shape)\n",
    "print(\"X_test:\", X_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We have predict the classification of wine. Hence we make a dictionary of all classifiers. We import the modules.\n",
    "import time\n",
    "\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn import tree\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "\n",
    "\n",
    "dict_classifiers = {\n",
    "    \"Logistic Regression\": LogisticRegression(),\n",
    "    \"Nearest Neighbors\": KNeighborsClassifier(),\n",
    "    \"Linear SVM\": SVC(),\n",
    "    \"Gradient Boosting Classifier\": GradientBoostingClassifier(n_estimators=500),\n",
    "    \"Decision Tree\": tree.DecisionTreeClassifier(),\n",
    "    \"Random Forest\": RandomForestClassifier(n_estimators=500),\n",
    "    \"Neural Net\": MLPClassifier(alpha = 1),\n",
    "    \"Naive Bayes\": GaussianNB(),\n",
    "    \n",
    "}\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import learning_curve \n",
    "def plot_learning_curve(estimator, title, X, y, ylim=None, cv=None,\n",
    "                        n_jobs=1, train_sizes=np.linspace(.6, 1.0, 5)):\n",
    "    \"\"\"\n",
    "    Generate a simple plot of the test and traning learning curve.\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    estimator : object type that implements the \"fit\" and \"predict\" methods\n",
    "        An object of that type which is cloned for each validation.\n",
    "\n",
    "    title : string\n",
    "        Title for the chart.\n",
    "\n",
    "    X : array-like, shape (n_samples, n_features)\n",
    "        Training vector, where n_samples is the number of samples and\n",
    "        n_features is the number of features.\n",
    "\n",
    "    y : array-like, shape (n_samples) or (n_samples, n_features), optional\n",
    "        Target relative to X for classification or regression;\n",
    "        None for unsupervised learning.\n",
    "\n",
    "    ylim : tuple, shape (ymin, ymax), optional\n",
    "        Defines minimum and maximum yvalues plotted.\n",
    "\n",
    "    cv : integer, cross-validation generator, optional\n",
    "        If an integer is passed, it is the number of folds (defaults to 3).\n",
    "        Specific cross-validation objects can be passed, see\n",
    "        sklearn.cross_validation module for the list of possible objects\n",
    "\n",
    "    n_jobs : integer, optional\n",
    "        Number of jobs to run in parallel (default 1).\n",
    "    \"\"\"\n",
    "    plt.figure()\n",
    "    plt.title(title)\n",
    "    if ylim is not None:\n",
    "        plt.ylim(*ylim)\n",
    "    plt.xlabel(\"Training examples\")\n",
    "    plt.ylabel(\"Score\")\n",
    "    train_sizes, train_scores, test_scores = learning_curve(\n",
    "        estimator, X, y, cv=cv, n_jobs=n_jobs, train_sizes=train_sizes)\n",
    "    train_scores_mean = np.mean(train_scores, axis=1)\n",
    "    train_scores_std = np.std(train_scores, axis=1)\n",
    "    test_scores_mean = np.mean(test_scores, axis=1)\n",
    "    test_scores_std = np.std(test_scores, axis=1)\n",
    "    plt.grid()\n",
    "\n",
    "    plt.fill_between(train_sizes, train_scores_mean - train_scores_std,\n",
    "                     train_scores_mean + train_scores_std, alpha=0.1,\n",
    "                     color=\"r\")\n",
    "    plt.fill_between(train_sizes, test_scores_mean - test_scores_std,\n",
    "                     test_scores_mean + test_scores_std, alpha=0.1, color=\"g\")\n",
    "    plt.plot(train_sizes, train_scores_mean, 'o-', color=\"r\",\n",
    "             label=\"Training score\")\n",
    "    plt.plot(train_sizes, test_scores_mean, 'o-', color=\"g\",\n",
    "             label=\"Cross-validation score\")\n",
    "\n",
    "    plt.legend(loc=\"best\")\n",
    "    return plt\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import precision_recall_fscore_support, confusion_matrix\n",
    "def batch_classify(X_train, Y_train, X_test, Y_test, no_classifiers = 5, verbose = True):\n",
    "    \"\"\"\n",
    "    This method, takes as input the X, Y matrices of the Train and Test set.\n",
    "    And fits them on all of the Classifiers specified in the dict_classifier.\n",
    "    The trained models, and accuracies are saved in a dictionary. The reason to use a dictionary\n",
    "    is because it is very easy to save the whole dictionary with the pickle module.\n",
    "    \n",
    "     \"\"\"\n",
    "    \n",
    "    dict_models = {}\n",
    "    for classifier_name, classifier in list(dict_classifiers.items())[:no_classifiers]:\n",
    "        t_start = time.clock()\n",
    "        classifier.fit(X_train, Y_train)\n",
    "        performance = precision_recall_fscore_support(Y_test,classifier.predict(X_test));\n",
    "        t_end = time.clock()\n",
    "        \n",
    "        t_diff = t_end - t_start\n",
    "        train_score = classifier.score(X_train, Y_train)\n",
    "        test_score = classifier.score(X_test, Y_test)\n",
    "        \n",
    "        dict_models[classifier_name] = {'model': classifier, 'train_score': train_score, 'test_score': test_score, 'train_time': t_diff, 'fscore': performance[2][1]}\n",
    "        if verbose:\n",
    "            print(\"trained {c} in {f:.2f} s\".format(c=classifier_name, f=t_diff))\n",
    "    return dict_models\n",
    "\n",
    "\n",
    "\n",
    "def display_dict_models(dict_models, sort_by='test_score'):\n",
    "    cls = [key for key in dict_models.keys()]\n",
    "    test_s = [dict_models[key]['test_score'] for key in cls]\n",
    "    training_s = [dict_models[key]['train_score'] for key in cls]\n",
    "    training_t = [dict_models[key]['train_time'] for key in cls]\n",
    "    f_score = [dict_models[key]['fscore'] for key in cls]\n",
    "    \n",
    "    df_ = pd.DataFrame(data=np.zeros(shape=(len(cls),5)), columns = ['classifier', 'train_score', 'test_score', 'train_time','fscore'])\n",
    "    for ii in range(0,len(cls)):\n",
    "        df_.loc[ii, 'classifier'] = cls[ii]\n",
    "        df_.loc[ii, 'train_score'] = training_s[ii]\n",
    "        df_.loc[ii, 'test_score'] = test_s[ii]\n",
    "        df_.loc[ii, 'train_time'] = training_t[ii]\n",
    "        df_.loc[ii, 'fscore'] = f_score[ii]\n",
    "    \n",
    "    display(df_.sort_values(by=sort_by, ascending=False))\n",
    "    \n",
    " \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\sklearn\\linear_model\\logistic.py:433: FutureWarning: Default solver will be changed to 'lbfgs' in 0.22. Specify a solver to silence this warning.\n",
      "  FutureWarning)\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\sklearn\\svm\\base.py:196: FutureWarning: The default value of gamma will change from 'auto' to 'scale' in version 0.22 to account better for unscaled features. Set gamma explicitly to 'auto' or 'scale' to avoid this warning.\n",
      "  \"avoid this warning.\", FutureWarning)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Logistic Regression in 0.04 s\n",
      "trained Nearest Neighbors in 0.03 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Linear SVM in 1.47 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Gradient Boosting Classifier in 1.52 s\n",
      "trained Decision Tree in 0.03 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Random Forest in 2.46 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "trained Neural Net in 2.11 s\n",
      "trained Naive Bayes in 0.00 s\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:13: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  del sys.path[0]\n",
      "C:\\Users\\Prabhjyot\\Anaconda3\\Anaconda4\\lib\\site-packages\\ipykernel_launcher.py:16: DeprecationWarning: time.clock has been deprecated in Python 3.3 and will be removed from Python 3.8: use time.perf_counter or time.process_time instead\n",
      "  app.launch_new_instance()\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>classifier</th>\n",
       "      <th>train_score</th>\n",
       "      <th>test_score</th>\n",
       "      <th>train_time</th>\n",
       "      <th>fscore</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Gradient Boosting Classifier</td>\n",
       "      <td>0.999560</td>\n",
       "      <td>0.995897</td>\n",
       "      <td>1.524291</td>\n",
       "      <td>0.991984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.999560</td>\n",
       "      <td>0.995897</td>\n",
       "      <td>2.460993</td>\n",
       "      <td>0.991984</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.999560</td>\n",
       "      <td>0.983590</td>\n",
       "      <td>0.026678</td>\n",
       "      <td>0.968254</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression</td>\n",
       "      <td>0.983506</td>\n",
       "      <td>0.977436</td>\n",
       "      <td>0.037747</td>\n",
       "      <td>0.955645</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Neural Net</td>\n",
       "      <td>0.979547</td>\n",
       "      <td>0.972308</td>\n",
       "      <td>2.106541</td>\n",
       "      <td>0.945455</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.973389</td>\n",
       "      <td>0.966667</td>\n",
       "      <td>0.003933</td>\n",
       "      <td>0.937319</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nearest Neighbors</td>\n",
       "      <td>0.957115</td>\n",
       "      <td>0.938974</td>\n",
       "      <td>0.029151</td>\n",
       "      <td>0.876171</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Linear SVM</td>\n",
       "      <td>0.976688</td>\n",
       "      <td>0.935385</td>\n",
       "      <td>1.469725</td>\n",
       "      <td>0.863043</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     classifier  train_score  test_score  train_time    fscore\n",
       "3  Gradient Boosting Classifier     0.999560    0.995897    1.524291  0.991984\n",
       "5                 Random Forest     0.999560    0.995897    2.460993  0.991984\n",
       "4                 Decision Tree     0.999560    0.983590    0.026678  0.968254\n",
       "0           Logistic Regression     0.983506    0.977436    0.037747  0.955645\n",
       "6                    Neural Net     0.979547    0.972308    2.106541  0.945455\n",
       "7                   Naive Bayes     0.973389    0.966667    0.003933  0.937319\n",
       "1             Nearest Neighbors     0.957115    0.938974    0.029151  0.876171\n",
       "2                    Linear SVM     0.976688    0.935385    1.469725  0.863043"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dict_models = batch_classify(X_train, Type_train, X_test, Type_test, no_classifiers = 8)\n",
    "display_dict_models(dict_models)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
